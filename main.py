import asyncio
from concurrent.futures import ThreadPoolExecutor
from io import BytesIO

import pandas as pd
import streamlit as st

from src import logger
from src.common.consts import ALLOWED_EXTENSIONS, ALLOWED_EXTENSIONS_WITH_ZIP, OUTPUT_DTYPE_DICT, OUTPUT_STR_COLUMNS
from src.common.models import ReportFile, ReportFileList, reset_category_id_to_name_ko_dict
from src.processor.generator import Generator
from src.processor.reader import FileReader
from src.utils.google_drive import GoogleDriveHelper
from src.utils.io import get_current_datetime, get_suffix, unzip_as_dict

gd_helper = GoogleDriveHelper()

if "category_id_to_name_ko_dict" not in st.session_state:
    reset_category_id_to_name_ko_dict()


def read_report_file(file, name=None) -> ReportFile:
    name = file.name if name is None else name
    extension = get_suffix(name)
    file_reader = FileReader(file=file, filetype=extension, clean=True)
    return ReportFile(name=name, content=file_reader.text)


def read_report_files_concurrently(files, names) -> ReportFileList:
    with ThreadPoolExecutor() as executor:
        return ReportFileList(executor.map(read_report_file, files, names))


async def run_llm_concurrently(report_file_list, category_id):
    generator = Generator()

    tasks = []
    for report_file in report_file_list:
        tasks.append(generator.agenerate(category=category_id, input_text=report_file.content))
    results = await asyncio.gather(*tasks, return_exceptions=True)
    return results


def raise_error(msg="Error", e=Exception):
    msg = f"{msg}: {e.__class__.__name__}: {e}"
    st.error(msg)
    logger.error(msg)


# https://docs.streamlit.io/library/api-reference/utilities/st.set_page_config
st.set_page_config(
    page_title="AI ê¸°ë°˜ ë¯¸ë˜ì—­ëŸ‰ í‰ê°€ ë„êµ¬", page_icon="ğŸ§Š", layout="centered", initial_sidebar_state="auto"  # "wide",
)

# #  Hide sidebar menu
# st.markdown(
#     # [data-testid="collapsedControl"] {
#     """
#     <style>
#         section[data-testid="stSidebar"][aria-expanded="true"]{
#             display: none;
#         }
#     </style>
#     """,
#     unsafe_allow_html=True,
# )

# Configure Streamlit page and state
st.title("AI ê¸°ë°˜ ë¯¸ë˜ì—­ëŸ‰ í‰ê°€ ë„êµ¬")
st.markdown("#### ìˆ™ëª…ì—¬ëŒ€ SSK ì—°êµ¬ì‚¬ì—… AI-CALIíŒ€ ê°œë°œ")
st.write(
    "ì´ ì ìˆ˜ëŠ” ì—°êµ¬ì§„ì´ ê°œë°œí•œ ì±„ì ê¸°ì¤€ì„ í™œìš©í•˜ì—¬ GPT-4ê°€ ì±„ì ì„ ì‹œí–‰í•œ ê²°ê³¼ë¡œ, "
    + "í–¥í›„ ì±„ì ì˜ ì‹ ë¢°ë„ì™€ íƒ€ë‹¹ë„ë¥¼ í‰ê°€í•˜ê³  ê°œì„ í•˜ê¸° ìœ„í•œ ì—°êµ¬ìë£Œë¡œ í™œìš©ë©ë‹ˆë‹¤. "
    + "í˜„ì¬ ë‹¨ê³„ì—ì„œ GPT-4ì˜ ì±„ì ê²°ê³¼ëŠ” ì‹¤ì œ í•´ë‹¹ ì—­ëŸ‰ì˜ íŠ¹ì„±ì„ ì¶©ë¶„íˆ ë°˜ì˜í•˜ê³  ìˆì§€ ì•Šì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, í•´ì„ê³¼ ì‚¬ìš© ì‹œ ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤"
)

with st.form("input"):
    category_id_selected = st.selectbox(
        "ì—­ëŸ‰",
        options=tuple(st.session_state["category_id_to_name_ko_dict"].keys()),
        format_func=lambda x: st.session_state["category_id_to_name_ko_dict"][x],
        # index=None,
        # placeholder="Select contact method...",
    )
    upload_files = st.file_uploader(
        f"ê³¼ì œ íŒŒì¼ ì—…ë¡œë“œ({' '.join(ALLOWED_EXTENSIONS_WITH_ZIP)})",
        accept_multiple_files=True,
        type=[ext[1:] for ext in ALLOWED_EXTENSIONS_WITH_ZIP],
    )
    # for filename, content in file_info.items():
    #     src_path = tgt_dir / filename
    #     async with aiofiles.open(src_path, "wb") as f:
    #         await f.write(content)
    #         logger.info(f"File uploaded to {src_path}")

    submitted = st.form_submit_button("í‰ê°€í•˜ê¸°")


if submitted:
    if not upload_files:
        st.error("1ê°œ ì´ìƒì˜ íŒŒì¼ì„ ì²¨ë¶€í•´ì£¼ì„¸ìš”.")
        st.stop()
    logger.info(f"File uploaded: {[file.name for file in upload_files]}")

    with st.spinner("íŒŒì¼ì„ ì½ê³  ìˆìŠµë‹ˆë‹¤..."):
        files_dict = dict()
        for upload_file in upload_files:
            suffix = get_suffix(upload_file.name)
            if suffix == ".zip":
                _files_dict = unzip_as_dict(upload_file, return_as_file=True)
                for filename, file in _files_dict.items():
                    if (ext := get_suffix(filename)) not in ALLOWED_EXTENSIONS:
                        raise_error(f"The {upload_file.name} file include unsupported file type: {ext}")

                files_dict.update(_files_dict)

            else:
                files_dict[upload_file.name] = upload_file

        try:
            input_file_list = read_report_files_concurrently(files_dict.values(), files_dict.keys())
            st.write(f"ì´ {len(input_file_list)}ê°œ íŒŒì¼ì„ ì½ì—ˆìŠµë‹ˆë‹¤.")
            logger.info(f"File loaded: {[file.name for file in input_file_list]}")
        except Exception as e:
            raise_error("Cannot read certain file. Make sure certain files are not corrupted or encrypted", e)
            st.stop()

    with st.spinner("í‰ê°€ì¤‘ì…ë‹ˆë‹¤... ì•½ 1~2ë¶„ ì†Œìš”ë©ë‹ˆë‹¤."):
        # Run LLM
        logger.info("Start to run LLM...")
        results = asyncio.run(run_llm_concurrently(input_file_list, category_id_selected))
        assert len(results) == len(input_file_list)

        stu_id_base = get_current_datetime(format="%y%m%d_%H%M%S")
        total_results = []
        for idx, (report_file, result) in enumerate(zip(input_file_list, results), start=1):
            _result = {"STU ID": f"{stu_id_base}_{idx}", "ë¹„ê³ ": ""}
            if isinstance(result, Exception):
                if len(input_file_list) == 1:
                    raise_error("Error raise", result)
                    st.stop()
                else:
                    _result["ë¹„ê³ "] = result
            else:
                _result.update(result["score_info"])
                _result.update({"ì‚¬ìš© ëª¨ë¸ëª…": result["model_name"]})
            _result.update({"ì›ë¬¸íŒŒì¼ëª…": report_file.name, "ì›ë¬¸ ë‚´ìš©": report_file.content})

            total_results.append(_result)

            # ëª¨ë“  ê²°ê³¼ì— ì¼ë¶€ í‚¤ê°’ì´ ì—†ëŠ” ê²½ìš°ê°€ ìˆì„ ìˆ˜ ìˆê¸°ì—, êµ¬ì¡° ë§ì¶°ì£¼ê¸° ìœ„í•´ ë¹ˆ ë°ì´í„°í”„ë ˆì„ì„ ë¨¼ì € ìƒì„±
            result_df = pd.DataFrame(columns=OUTPUT_DTYPE_DICT.keys())
            new_df = pd.DataFrame(total_results)
            result_df = pd.concat([result_df, new_df], ignore_index=True)
            result_df.loc[:, OUTPUT_STR_COLUMNS] = result_df[OUTPUT_STR_COLUMNS].fillna("")
            result_df = result_df.astype(OUTPUT_DTYPE_DICT)

    with st.spinner("ê²°ê³¼ë¥¼ êµ¬ê¸€ë“œë¼ì´ë¸Œì— ì—…ë¡œë“œí•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
        # encoding = "utf-8-sig"
        # filename = f"report_{stu_id_base}.csv"
        # result_csv_bytes = result_df.to_csv(index=False).encode(encoding)
        filename = f"report_{stu_id_base}.xlsx"
        output = BytesIO()
        with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
            result_df.to_excel(writer, index=False)
        result_xlsx_bytes = output.getvalue()

        # Save to google drive
        try:
            # folder = gd_helper.create_folder(stu_id_base)
            file = gd_helper.upload_byte_obj(filename, result_xlsx_bytes)  # , folder_id=folder["id"])

        except Exception as e:
            raise_error("Cannot upload result to google drive", e)
        else:
            st.link_button("ê²°ê³¼ Google driveì—ì„œ í™•ì¸í•˜ê¸°", url=file["alternateLink"])  # folder["alternateLink"])
            # embedLink: preview, webContentLink: downlaod
            # st.link_button("Google driveì—ì„œ í™•ì¸í•˜ê¸°", url=file["alternateLink"])

        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì¶”ê°€
        # st.download_button("ê²°ê³¼ ë‹¤ìš´ë°›ê¸°", result_csv_bytes, filename, "text/csv", key="download-csv")
        st.download_button(
            "ê²°ê³¼ íŒŒì¼ë¡œ ë‹¤ìš´ë°›ê¸°",
            result_xlsx_bytes,
            filename,
            "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            key="download-xlsx",
        )

        st.success("í‰ê°€ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ê²°ê³¼ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

# st.write(f"ê¸¸ì´: {len(content)} ì")
# st.write(f"ë¹„ìš©: {cost:.3f} usd($)")
